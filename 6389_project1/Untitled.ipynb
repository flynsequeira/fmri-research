{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nibabel as nib\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    " class Model:\n",
    "    # https: // www.tensorflow.org / tutorials / images / cnn\n",
    "    def __init__(self, train_x_data, train_y_data, test_x_data, test_y_data, test_patients_numbers):\n",
    "        self.model = models.Sequential()\n",
    "        self.model.add(layers.Conv2D(filters=128, kernel_size=(3, 3), activation='relu', input_shape=(199, 190, 1)))\n",
    "        self.model.add(layers.MaxPooling2D((2, 2)))\n",
    "        self.model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "        self.model.add(layers.MaxPooling2D((2, 2)))\n",
    "        self.model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "        self.model.add(layers.Flatten())\n",
    "        self.model.add(layers.Dense(64, activation='relu'))\n",
    "        self.model.add(layers.Dense(2))\n",
    "        # self.model.add(layers.Activation('softmax'))\n",
    "        self.train_x = train_x_data\n",
    "        self.train_y = train_y_data\n",
    "        self.test_x = test_x_data\n",
    "        self.test_y = test_y_data\n",
    "        self.test_patients_numbers = test_patients_numbers\n",
    "        # self.checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath='training-checkpoint.ckpt',\n",
    "        #                                                      save_weights_only=True,\n",
    "        #                                                      verbose=1)\n",
    "\n",
    "    def use_pretrained_model(self):\n",
    "        self.model.load_weights('training-checkpoint.ckpt')\n",
    "\n",
    "    def train(self, optimizer='adam', loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)):\n",
    "        self.model.compile(optimizer=optimizer,\n",
    "                           loss=loss,\n",
    "                           metrics=['accuracy'])\n",
    "        history = self.model.fit(self.train_x, self.train_y, epochs=15,\n",
    "                                 validation_data=(self.test_x, self.test_y))\n",
    "\n",
    "        return history\n",
    "\n",
    "    def test(self, unhealthy_threshold: int = 70):\n",
    "        current_number = 0\n",
    "        predictions = []\n",
    "        patient_slides_prediction = []\n",
    "        for slide_index, slide in enumerate(self.test_x):\n",
    "            if self.test_patients_numbers[slide_index] != current_number:\n",
    "                current_number += 1\n",
    "                if patient_slides_prediction.count(0) >= unhealthy_threshold:\n",
    "                    predictions.append(patient_slides_prediction.count(1)/len(patient_slides_prediction))\n",
    "                else:\n",
    "                    predictions.append(patient_slides_prediction.count(1)/len(patient_slides_prediction))\n",
    "                patient_slides_prediction = []\n",
    "            pred = self.model.predict(np.array([slide]))\n",
    "            patient_slides_prediction.append(np.argmax(pred[0]))\n",
    "        return predictions\n",
    "\n",
    "    def accuracy(self, predictions):\n",
    "        # print(len(prediction))\n",
    "        print(predictions)\n",
    "        # return sum(np.array(predictions) == np.array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]))/20\n",
    "\n",
    "    def accuracy_graph(self, history_data):\n",
    "        # plt.plot(history.history_data['accuracy'], label='accuracy')\n",
    "        # plt.plot(history.history_data['val_accuracy'], label='val_accuracy')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Accuracy')\n",
    "        plt.ylim([0.5, 1])\n",
    "        plt.legend(loc='lower right')\n",
    "\n",
    "\n",
    "def image_resize(image, width=None, height=None, inter=cv2.INTER_AREA):\n",
    "    # initialize the dimensions of the image to be resized and\n",
    "    # grab the image size\n",
    "    dim = None\n",
    "    (h, w) = image.shape[:2]\n",
    "\n",
    "    # if both the width and height are None, then return the\n",
    "    # original image\n",
    "    if width is None and height is None:\n",
    "        return image\n",
    "\n",
    "    # check to see if the width is None\n",
    "    if width is None:\n",
    "        # calculate the ratio of the height and construct the\n",
    "        # dimensions\n",
    "        r = height / float(h)\n",
    "        dim = (int(w * r), height)\n",
    "\n",
    "    # otherwise, the height is None\n",
    "    else:\n",
    "        # calculate the ratio of the width and construct the\n",
    "        # dimensions\n",
    "        r = width / float(w)\n",
    "        dim = (width, int(h * r))\n",
    "\n",
    "    # resize the image\n",
    "    resized = cv2.resize(image, dim, interpolation=inter)\n",
    "\n",
    "    # return the resized image\n",
    "    return resized\n",
    "\n",
    "\n",
    "# Training or Testing\n",
    "def get_data(data_category='Training'):\n",
    "    all_slides = []\n",
    "    labels = []\n",
    "    patient_numbers = []\n",
    "    current_counter = 0\n",
    "    for label in ['patient', 'health']:\n",
    "        for i in range(1, 11):\n",
    "            try:\n",
    "                data_registered_space = nib.load('./fmri_dataset/' + data_category + '/' + label +\n",
    "                                                 '/sub' + str(i) + '/T1_bet_2_0413.nii.gz')\n",
    "            except:\n",
    "                if label == 'patient':\n",
    "                    continue\n",
    "                else:\n",
    "                    return np.array(all_slides), np.array(labels), patient_numbers\n",
    "            whole_brain = data_registered_space.get_fdata()\n",
    "            # Reshape 2D into 3D where axis-2 is the rgb value, where you use greyscale instead of rgb\n",
    "            # eg. Greyscale value - 0.5 is represented as [0.5]\n",
    "            patients_slides = [np.expand_dims(slide, axis=2) for slide in whole_brain]\n",
    "            if label == 'patient':\n",
    "                for _ in whole_brain:\n",
    "                    patient_numbers.append(current_counter)\n",
    "                    labels.append(0)\n",
    "            else:\n",
    "                for _ in whole_brain:\n",
    "                    patient_numbers.append(current_counter)\n",
    "                    labels.append(1)\n",
    "            all_slides.extend(patients_slides)\n",
    "            current_counter += 1\n",
    "    return np.array(all_slides), np.array(labels), patient_numbers\n",
    "\n",
    "\n",
    "# train_x, train_y, train_patient_numbers = get_data('Training')\n",
    "# test_x, test_y, test_patient_numbers = get_data('Testing')\n",
    "# print(set(train_patient_numbers))\n",
    "# print(set(test_patient_numbers))\n",
    "# cnn_model = Model(train_x, train_y, test_x, test_y, test_patient_numbers)\n",
    "# # # print('pretraining')\n",
    "# # cnn_model.use_pretrained_model()\n",
    "# history = cnn_model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, train_y, train_patient_numbers = get_data('Training')\n",
    "test_x, test_y, test_patient_numbers = get_data('Testing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model = Model(train_x, train_y, test_x, test_y, test_patient_numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model.train(loss=tf.keras.losses.binary_crossentropy,\n",
    "              optimizer=tf.keras.optimizers.Adam(lr=0.1),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device mapping:\n",
      "/job:localhost/replica:0/task:0/device:XLA_CPU:0 -> device: XLA_CPU device\n",
      "/job:localhost/replica:0/task:0/device:XLA_GPU:0 -> device: XLA_GPU device\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sess = tf.compat.v1.Session(config=tf.compat.v1.ConfigProto(log_device_placement=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:XLA_GPU:0', device_type='XLA_GPU')]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices('XLA_GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
