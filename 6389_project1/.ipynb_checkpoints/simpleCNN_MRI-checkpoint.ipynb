{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72,
     "resources": {
      "http://localhost:8080/nbextensions/google.colab/files.js": {
       "data": "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",
       "headers": [
        [
         "content-type",
         "application/javascript"
        ]
       ],
       "ok": true,
       "status": 200,
       "status_text": ""
      }
     }
    },
    "executionInfo": {
     "elapsed": 7402,
     "status": "ok",
     "timestamp": 1602643760879,
     "user": {
      "displayName": "MAX CG",
      "photoUrl": "",
      "userId": "17153937431201736559"
     },
     "user_tz": 300
    },
    "id": "xVa7_oqU-V3g",
    "outputId": "2772eab6-4ea2-4101-92de-3c94cb00e076"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "     <input type=\"file\" id=\"files-3f2213b1-4681-4265-90f5-430f5f6a3df9\" name=\"files[]\" multiple disabled\n",
       "        style=\"border:none\" />\n",
       "     <output id=\"result-3f2213b1-4681-4265-90f5-430f5f6a3df9\">\n",
       "      Upload widget is only available when the cell has been executed in the\n",
       "      current browser session. Please rerun this cell to enable.\n",
       "      </output>\n",
       "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving input_3Dimage.py to input_3Dimage (5).py\n"
     ]
    }
   ],
   "source": [
    "from google.colab import files\n",
    "src = list(files.upload().values())[0]\n",
    "open('input_3Dimage.py', 'wb').write(src)\n",
    "import input_3Dimage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nibabel\n",
      "  Downloading nibabel-3.1.1-py3-none-any.whl (3.3 MB)\n",
      "Requirement already satisfied: numpy>=1.13 in c:\\users\\singh\\anaconda3\\lib\\site-packages (from nibabel) (1.18.3)\n",
      "Requirement already satisfied: packaging>=14.3 in c:\\users\\singh\\appdata\\roaming\\python\\python37\\site-packages (from nibabel) (20.1)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\singh\\appdata\\roaming\\python\\python37\\site-packages (from packaging>=14.3->nibabel) (2.4.6)\n",
      "Requirement already satisfied: six in c:\\users\\singh\\anaconda3\\lib\\site-packages (from packaging>=14.3->nibabel) (1.14.0)\n",
      "Installing collected packages: nibabel\n",
      "Successfully installed nibabel-3.1.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: pip is being invoked by an old script wrapper. This will fail in a future version of pip.\n",
      "Please see https://github.com/pypa/pip/issues/5599 for advice on fixing the underlying issue.\n",
      "To avoid this problem you can invoke Python with '-m pip' instead of running pip directly.\n",
      "WARNING: You are using pip version 20.0.2; however, version 20.2.3 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\Singh\\Anaconda3\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install nibabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "executionInfo": {
     "elapsed": 609,
     "status": "ok",
     "timestamp": 1602646883900,
     "user": {
      "displayName": "MAX CG",
      "photoUrl": "",
      "userId": "17153937431201736559"
     },
     "user_tz": 300
    },
    "id": "94wtTx5jL5uI"
   },
   "outputs": [],
   "source": [
    "import nibabel as nib\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"   #if like me you do not have a lot of memory in your GPU\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\" #then these two lines force keras to use your CPU\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv3D, MaxPooling3D, Dropout, BatchNormalization\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 589
    },
    "executionInfo": {
     "elapsed": 852,
     "status": "error",
     "timestamp": 1602648099389,
     "user": {
      "displayName": "MAX CG",
      "photoUrl": "",
      "userId": "17153937431201736559"
     },
     "user_tz": 300
    },
    "id": "5dSIc03vMsZ8",
    "outputId": "133bf91f-bd56-43f3-fada-4fbcbb43160b"
   },
   "outputs": [],
   "source": [
    "trainx = [(nib.load('./Training/health/sub'+str(i)+'/T1_bet_2_0413.nii.gz').get_fdata()) for i in range(1,11)]\n",
    "trainx2 = [nib.load('./Training/patient/sub'+str(i)+'/T1_bet_2_0413.nii.gz').get_fdata() for i in range(1,11)]\n",
    "trainx.extend(trainx2)\n",
    "trainx = np.array(trainx)\n",
    "trainy = [0 for i in range(0,10)]\n",
    "trainy.extend([1 for i in range(0,10)])\n",
    "testx = [nib.load('./Testing/health/sub'+str(i)+'/T1_bet_2_0413.nii.gz').get_fdata() for i in range(1,6)]\n",
    "testx2 = [nib.load('./Testing/patient/sub'+str(i)+'/T1_bet_2_0413.nii.gz').get_fdata() for i in range(1,6)]\n",
    "testx.extend(testx2)\n",
    "testx = np.array(testx)\n",
    "testy = [0 for i in range(0,5)]\n",
    "testy.extend([1 for i in range(0,5)])\n",
    "trainx = np.expand_dims(trainx, axis = 4)\n",
    "testx = np.expand_dims(testx, axis = 4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://towardsdatascience.com/step-by-step-implementation-3d-convolutional-neural-network-in-keras-12efbdd7b130"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "executionInfo": {
     "elapsed": 467,
     "status": "ok",
     "timestamp": 1602647028425,
     "user": {
      "displayName": "MAX CG",
      "photoUrl": "",
      "userId": "17153937431201736559"
     },
     "user_tz": 300
    },
    "id": "uGRiRFzjM4Gh",
    "outputId": "799698b1-d59f-40b1-d5d7-e3a04943e9e0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Singh\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    }
   ],
   "source": [
    "# model \n",
    "# Create the model\n",
    "model = Sequential()\n",
    "model.add(Conv3D(32, kernel_size=(3, 3, 3), activation='relu', kernel_initializer='he_uniform', input_shape=trainx[0].shape))\n",
    "model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "model.add(BatchNormalization(center=True, scale=True))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Conv3D(64, kernel_size=(3, 3, 3), activation='relu', kernel_initializer='he_uniform'))\n",
    "model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "model.add(BatchNormalization(center=True, scale=True))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu', kernel_initializer='he_uniform'))\n",
    "model.add(Dense(256, activation='relu', kernel_initializer='he_uniform'))\n",
    "model.add(Dense(2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d_3 (Conv3D)            (None, 139, 197, 188, 32) 896       \n",
      "_________________________________________________________________\n",
      "max_pooling3d (MaxPooling3D) (None, 69, 98, 94, 32)    0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 69, 98, 94, 32)    128       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 69, 98, 94, 32)    0         \n",
      "_________________________________________________________________\n",
      "conv3d_4 (Conv3D)            (None, 67, 96, 92, 64)    55360     \n",
      "_________________________________________________________________\n",
      "max_pooling3d_1 (MaxPooling3 (None, 33, 48, 46, 64)    0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 33, 48, 46, 64)    256       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 33, 48, 46, 64)    0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 4663296)           0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               1193804032\n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 514       \n",
      "=================================================================\n",
      "Total params: 1,193,926,978\n",
      "Trainable params: 1,193,926,786\n",
      "Non-trainable params: 192\n",
      "_________________________________________________________________\n",
      "Train on 14 samples, validate on 6 samples\n",
      "Epoch 1/10\n"
     ]
    }
   ],
   "source": [
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=keras.optimizers.Adam(lr=0.001),\n",
    "              metrics=['accuracy'])\n",
    "model.summary()\n",
    "# Fit data to model\n",
    "history = model.fit(trainx, to_categorical(trainy),\n",
    "            batch_size=3,\n",
    "            epochs=10,\n",
    "            verbose=1,\n",
    "            validation_split=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "928.162476"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_shape =(4, 28, 28, 28, 1)\n",
    "x = tf.random.normal(input_shape)\n",
    "y = tf.keras.layers.Conv3D(\n",
    "2, 3, activation='relu', input_shape=input_shape[1:])(x)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "executionInfo": {
     "elapsed": 1133,
     "status": "ok",
     "timestamp": 1602647198310,
     "user": {
      "displayName": "MAX CG",
      "photoUrl": "",
      "userId": "17153937431201736559"
     },
     "user_tz": 300
    },
    "id": "f1aNDtaoN0E7",
    "outputId": "e4e9b0cf-e7ae-4460-e503-863e4e1cdd67"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 4, 9]"
      ]
     },
     "execution_count": 18,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[i**2 for i in [1,2,3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 582
    },
    "executionInfo": {
     "elapsed": 6329,
     "status": "error",
     "timestamp": 1602644263508,
     "user": {
      "displayName": "MAX CG",
      "photoUrl": "",
      "userId": "17153937431201736559"
     },
     "user_tz": 300
    },
    "id": "roGOwlp29AtK",
    "outputId": "e2b7a268-3383-4ee5-d508-e4d091a2bc96"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Singh\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\compat\\v2_compat.py:65: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n",
      "<bound method Tensor.get_shape of <tf.Tensor 'Reshape:0' shape=(?, 256, 256, 40, 1) dtype=float32>>\n",
      "<bound method Tensor.get_shape of <tf.Tensor 'Relu:0' shape=(?, 256, 256, 40, 32) dtype=float32>>\n",
      "<bound method Tensor.get_shape of <tf.Tensor 'MaxPool3D:0' shape=(?, 64, 64, 10, 32) dtype=float32>>\n",
      "<bound method Tensor.get_shape of <tf.Tensor 'Relu_1:0' shape=(?, 64, 64, 10, 64) dtype=float32>>\n",
      "<bound method Tensor.get_shape of <tf.Tensor 'MaxPool3D_1:0' shape=(?, 16, 16, 3, 64) dtype=float32>>\n",
      "<bound method Tensor.get_shape of <tf.Tensor 'Reshape_1:0' shape=(?, 49152) dtype=float32>>\n",
      "<bound method Tensor.get_shape of <tf.Tensor 'Relu_2:0' shape=(?, 1024) dtype=float32>>\n",
      "WARNING:tensorflow:From <ipython-input-21-0cf503ff5f54>:87: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "<bound method Tensor.get_shape of <tf.Tensor 'dropout/mul_1:0' shape=(?, 1024) dtype=float32>>\n",
      "<bound method Tensor.get_shape of <tf.Tensor 'add_3:0' shape=(?, 4) dtype=float32>>\n",
      "WARNING:tensorflow:From <ipython-input-21-0cf503ff5f54>:99: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-0cf503ff5f54>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    111\u001b[0m     \u001b[1;31m# Logging every 100th iteration in the training process.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    112\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m%\u001b[0m\u001b[1;36m5\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 113\u001b[1;33m         \u001b[0mtrain_accuracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeep_prob\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;36m1.0\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    114\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"step %d, training accuracy %g\"\u001b[0m\u001b[1;33m%\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_accuracy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m     \u001b[0mtrain_step\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeep_prob\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;36m0.5\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "# A simple CNN to predict certain characteristics of the human subject from MRI images.\n",
    "# 3d convolution is used in each layer.\n",
    "# Reference: https://www.tensorflow.org/get_started/mnist/pros, http://blog.naver.com/kjpark79/220783765651\n",
    "# Adjust needed for your dataset e.g., max pooling, convolution parameters, training_step, batch size, etc\n",
    "\n",
    "width = 256\n",
    "height = 256\n",
    "depth = 40\n",
    "nLabel = 4\n",
    "\n",
    "# Start TensorFlow InteractiveSession\n",
    "# from google.colab import files\n",
    "# src = list(files.upload().values*())[0]\n",
    "# open('input_3Dimage.py', 'wb').write(src)\n",
    "# import input_3Dimage\n",
    "\n",
    "# import input_3Dimage\n",
    "# import tensorflow as tf\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "# Placeholders (MNIST image:28x28pixels=784, label=10)\n",
    "x = tf.placeholder(tf.float32, shape=[None, width*height*depth]) # [None, 28*28]\n",
    "y_ = tf.placeholder(tf.float32, shape=[None, nLabel])  # [None, 10]\n",
    "\n",
    "## Weight Initialization\n",
    "# Create lots of weights and biases & Initialize with a small positive number as we will use ReLU\n",
    "def weight_variable(shape):\n",
    "  initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "  return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "  initial = tf.constant(0.1, shape=shape)\n",
    "  return tf.Variable(initial)\n",
    "\n",
    "## Convolution and Pooling\n",
    "# Convolution here: stride=1, zero-padded -> output size = input size\n",
    "def conv3d(x, W):\n",
    "  return tf.nn.conv3d(x, W, strides=[1, 1, 1, 1, 1], padding='SAME') # conv2d, [1, 1, 1, 1]\n",
    "\n",
    "# Pooling: max pooling over 2x2 blocks\n",
    "def max_pool_2x2(x):  # tf.nn.max_pool. ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1]\n",
    "  return tf.nn.max_pool3d(x, ksize=[1, 4, 4, 4, 1], strides=[1, 4, 4, 4, 1], padding='SAME')\n",
    "\n",
    "\n",
    "## First Convolutional Layer\n",
    "# Conv then Max-pooling. 1st layer will have 32 features for each 5x5 patch. (1 feature -> 32 features)\n",
    "W_conv1 = weight_variable([5, 5, 5, 1, 32])  # shape of weight tensor = [5,5,1,32]\n",
    "b_conv1 = bias_variable([32])  # bias vector for each output channel. = [32]\n",
    "\n",
    "# Reshape 'x' to a 4D tensor (2nd dim=image width, 3rd dim=image height, 4th dim=nColorChannel)\n",
    "x_image = tf.reshape(x, [-1,width,height,depth,1]) # [-1,28,28,1]\n",
    "print(x_image.get_shape) # (?, 256, 256, 40, 1)  # -> output image: 28x28 x1\n",
    "\n",
    "# x_image * weight tensor + bias -> apply ReLU -> apply max-pool\n",
    "h_conv1 = tf.nn.relu(conv3d(x_image, W_conv1) + b_conv1)  # conv2d, ReLU(x_image * weight + bias)\n",
    "print(h_conv1.get_shape) # (?, 256, 256, 40, 32)  # -> output image: 28x28 x32\n",
    "h_pool1 = max_pool_2x2(h_conv1)  # apply max-pool \n",
    "print(h_pool1.get_shape) # (?, 128, 128, 20, 32)  # -> output image: 14x14 x32\n",
    "\n",
    "\n",
    "## Second Convolutional Layer\n",
    "# Conv then Max-pooling. 2nd layer will have 64 features for each 5x5 patch. (32 features -> 64 features)\n",
    "W_conv2 = weight_variable([5, 5, 5, 32, 64]) # [5, 5, 32, 64]\n",
    "b_conv2 = bias_variable([64]) # [64]\n",
    "\n",
    "h_conv2 = tf.nn.relu(conv3d(h_pool1, W_conv2) + b_conv2)  # conv2d, .ReLU(x_image * weight + bias)\n",
    "print(h_conv2.get_shape) # (?, 128, 128, 20, 64)  # -> output image: 14x14 x64\n",
    "h_pool2 = max_pool_2x2(h_conv2)  # apply max-pool \n",
    "print(h_pool2.get_shape) # (?, 64, 64, 10, 64)    # -> output image: 7x7 x64\n",
    "\n",
    "\n",
    "## Densely Connected Layer (or fully-connected layer)\n",
    "# fully-connected layer with 1024 neurons to process on the entire image\n",
    "W_fc1 = weight_variable([16*16*3*64, 1024])  # [7*7*64, 1024]\n",
    "b_fc1 = bias_variable([1024]) # [1024]]\n",
    "\n",
    "h_pool2_flat = tf.reshape(h_pool2, [-1, 16*16*3*64])  # -> output image: [-1, 7*7*64] = 3136\n",
    "print(h_pool2_flat.get_shape)  # (?, 2621440)\n",
    "h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)  # ReLU(h_pool2_flat x weight + bias)\n",
    "print(h_fc1.get_shape) # (?, 1024)  # -> output: 1024\n",
    "\n",
    "## Dropout (to reduce overfitting; useful when training very large neural network)\n",
    "# We will turn on dropout during training & turn off during testing\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)\n",
    "print(h_fc1_drop.get_shape)  # -> output: 1024\n",
    "\n",
    "## Readout Layer\n",
    "W_fc2 = weight_variable([1024, nLabel]) # [1024, 10]\n",
    "b_fc2 = bias_variable([nLabel]) # [10]\n",
    "\n",
    "y_conv = tf.matmul(h_fc1_drop, W_fc2) + b_fc2\n",
    "print(y_conv.get_shape)  # -> output: 10\n",
    "\n",
    "## Train and Evaluate the Model\n",
    "# set up for optimization (optimizer:ADAM)\n",
    "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=y_conv))\n",
    "train_step = tf.train.AdamOptimizer(1e-3).minimize(cross_entropy)  # 1e-4\n",
    "correct_prediction = tf.equal(tf.argmax(y_conv,1), tf.argmax(y_,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# Include keep_prob in feed_dict to control dropout rate.\n",
    "for i in range(100):\n",
    "    # batch = get_data_MRI(sess,'train',20)\n",
    "#     batch = input_3Dimage.get_data_MRI(sess,'train',20)\n",
    "    batch = train_healthy.extend(train_patient)\n",
    "    # Logging every 100th iteration in the training process.\n",
    "    if i%5 == 0:\n",
    "        train_accuracy = accuracy.eval(feed_dict={x:batch[0], y_: batch[1], keep_prob: 1.0})\n",
    "        print(\"step %d, training accuracy %g\"%(i, train_accuracy))\n",
    "    train_step.run(feed_dict={x: batch[0], y_: batch[1], keep_prob: 0.5})\n",
    "\n",
    "# Evaulate our accuracy on the test data\n",
    "testset = get_data_MRI(sess,'test',30)\n",
    "print(\"test accuracy %g\"%accuracy.eval(feed_dict={x: testset[0], y_: teseset[1], keep_prob: 1.0}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "afiGqmPmL8nd"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cFx5NPY99Jhs"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPf4bqqjO136zomoBInP6Om",
   "collapsed_sections": [],
   "name": "simpleCNN_MRI.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
